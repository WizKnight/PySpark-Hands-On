{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPLOYEE_ID</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>PHONE_NUMBER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_ID</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>COMMISSION_PCT</th>\n",
       "      <th>MANAGER_ID</th>\n",
       "      <th>DEPARTMENT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>Donald</td>\n",
       "      <td>OConnell</td>\n",
       "      <td>DOCONNEL</td>\n",
       "      <td>650.507.9833</td>\n",
       "      <td>21-JUN-07</td>\n",
       "      <td>SH_CLERK</td>\n",
       "      <td>2600</td>\n",
       "      <td>-</td>\n",
       "      <td>124</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>Grant</td>\n",
       "      <td>DGRANT</td>\n",
       "      <td>650.507.9844</td>\n",
       "      <td>13-JAN-08</td>\n",
       "      <td>SH_CLERK</td>\n",
       "      <td>2600</td>\n",
       "      <td>-</td>\n",
       "      <td>124</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Whalen</td>\n",
       "      <td>JWHALEN</td>\n",
       "      <td>515.123.4444</td>\n",
       "      <td>17-SEP-03</td>\n",
       "      <td>AD_ASST</td>\n",
       "      <td>4400</td>\n",
       "      <td>-</td>\n",
       "      <td>101</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Hartstein</td>\n",
       "      <td>MHARTSTE</td>\n",
       "      <td>515.123.5555</td>\n",
       "      <td>17-FEB-04</td>\n",
       "      <td>MK_MAN</td>\n",
       "      <td>13000</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202</td>\n",
       "      <td>Pat</td>\n",
       "      <td>Fay</td>\n",
       "      <td>PFAY</td>\n",
       "      <td>603.123.6666</td>\n",
       "      <td>17-AUG-05</td>\n",
       "      <td>MK_REP</td>\n",
       "      <td>6000</td>\n",
       "      <td>-</td>\n",
       "      <td>201</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMPLOYEE_ID FIRST_NAME  LAST_NAME     EMAIL  PHONE_NUMBER  HIRE_DATE  \\\n",
       "0          198     Donald   OConnell  DOCONNEL  650.507.9833  21-JUN-07   \n",
       "1          199    Douglas      Grant    DGRANT  650.507.9844  13-JAN-08   \n",
       "2          200   Jennifer     Whalen   JWHALEN  515.123.4444  17-SEP-03   \n",
       "3          201    Michael  Hartstein  MHARTSTE  515.123.5555  17-FEB-04   \n",
       "4          202        Pat        Fay      PFAY  603.123.6666  17-AUG-05   \n",
       "\n",
       "     JOB_ID  SALARY COMMISSION_PCT MANAGER_ID  DEPARTMENT_ID  \n",
       "0  SH_CLERK    2600             -         124             50  \n",
       "1  SH_CLERK    2600             -         124             50  \n",
       "2   AD_ASST    4400             -         101             10  \n",
       "3    MK_MAN   13000             -         100             20  \n",
       "4    MK_REP    6000             -         201             20  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:\\PySpark\\data.csv', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise PySpark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PREDATOR:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise PySpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x162fb452fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data with spark (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('.\\data.csv')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV with Spark (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "|        110|      John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT|  8200|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header', 'true').csv('data.csv', inferSchema=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='EMPLOYEE_ID', _c1='FIRST_NAME', _c2='LAST_NAME', _c3='EMAIL', _c4='PHONE_NUMBER', _c5='HIRE_DATE', _c6='JOB_ID', _c7='SALARY', _c8='COMMISSION_PCT', _c9='MANAGER_ID', _c10='DEPARTMENT_ID'),\n",
       " Row(_c0='198', _c1='Donald', _c2='OConnell', _c3='DOCONNEL', _c4='650.507.9833', _c5='21-JUN-07', _c6='SH_CLERK', _c7='2600', _c8=' - ', _c9='124', _c10='50'),\n",
       " Row(_c0='199', _c1='Douglas', _c2='Grant', _c3='DGRANT', _c4='650.507.9844', _c5='13-JAN-08', _c6='SH_CLERK', _c7='2600', _c8=' - ', _c9='124', _c10='50')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Columns and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8', '_c9', '_c10']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c1: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select('_c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('_c1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|       _c1|      _c2|\n",
      "+----------+---------+\n",
      "|FIRST_NAME|LAST_NAME|\n",
      "|    Donald| OConnell|\n",
      "|   Douglas|    Grant|\n",
      "+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['_c1','_c2']).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('_c1', 'string'),\n",
       " ('_c2', 'string'),\n",
       " ('_c3', 'string'),\n",
       " ('_c4', 'string'),\n",
       " ('_c5', 'string'),\n",
       " ('_c6', 'string'),\n",
       " ('_c7', 'string'),\n",
       " ('_c8', 'string'),\n",
       " ('_c9', 'string'),\n",
       " ('_c10', 'string')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------+------+------------+---------+----------+-----------------+--------------+------------------+-----------------+\n",
      "|summary|               _c0|    _c1|     _c2|   _c3|         _c4|      _c5|       _c6|              _c7|           _c8|               _c9|             _c10|\n",
      "+-------+------------------+-------+--------+------+------------+---------+----------+-----------------+--------------+------------------+-----------------+\n",
      "|  count|                51|     51|      51|    51|          51|       51|        51|               51|            51|                51|               51|\n",
      "|   mean|            134.76|   null|    null|  null|        null|     null|      null|          6182.32|          null|114.83673469387755|             57.6|\n",
      "| stddev|33.631593504213456|   null|    null|  null|        null|     null|      null|4586.181771631927|          null|20.591611296406914|25.11686968666962|\n",
      "|    min|               100|   Adam|Atkinson|AFRIPP|515.123.4444|01-MAY-03|AC_ACCOUNT|            10000|            - |                - |               10|\n",
      "|    max|       EMPLOYEE_ID|William|  Whalen|WGIETZ|PHONE_NUMBER|HIRE_DATE|    ST_MAN|           SALARY|COMMISSION_PCT|        MANAGER_ID|    DEPARTMENT_ID|\n",
      "+-------+------------------+-------+--------+------+------------+---------+----------+-----------------+--------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding columns and Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|     _c6|   _c7|           _c8|       _c9|         _c10|  _c11|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|  JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|  null|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|SH_CLERK|  2600|            - |       124|           50|4600.0|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|SH_CLERK|  2600|            - |       124|           50|4600.0|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SALARY = '_c7'\n",
    "\n",
    "df_pyspark.withColumn('_c11', df_pyspark['_c7']+2000).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('_c11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|     _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|  JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03| AD_ASST|  4400|            - |       101|           10|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|        _c0|First_Name|      _c2|     _c3|         _c4|      _c5|     _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|  JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|SH_CLERK|  2600|            - |       124|           50|\n",
      "+-----------+----------+---------+--------+------------+---------+--------+------+--------------+----------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('_c1','First_Name').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Drop the columns\n",
    "df_pyspark.drop('_c0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Dropping null 0r na values\n",
    "\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## any == how\n",
    "\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Threshold\n",
    "\n",
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset: Drop nan values from a specific column\n",
    "\n",
    "df_pyspark.na.drop(how='any', subset=['_c8']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        _c0|       _c1|      _c2|     _c3|         _c4|      _c5|       _c6|   _c7|           _c8|       _c9|         _c10|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "|        198|    Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        199|   Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|  2600|            - |       124|           50|\n",
      "|        200|  Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|  4400|            - |       101|           10|\n",
      "|        201|   Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN| 13000|            - |       100|           20|\n",
      "|        202|       Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|  6000|            - |       201|           20|\n",
      "|        203|     Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|  6500|            - |       101|           40|\n",
      "|        204|   Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP| 10000|            - |       101|           70|\n",
      "|        205|   Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR| 12008|            - |       101|          110|\n",
      "|        206|   William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT|  8300|            - |       205|          110|\n",
      "|        100|    Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES| 24000|            - |        - |           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP| 17000|            - |       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP| 17000|            - |       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG|  9000|            - |       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|  6000|            - |       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|  4800|            - |       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|  4200|            - |       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR| 12008|            - |       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT|  9000|            - |       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling the missing values\n",
    "\n",
    "df_pyspark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling missing values with Mean, Mode, Median\n",
    "\n",
    "## Using Imputer functions\n",
    "\n",
    "#from pyspark.ml.feature import Imputer\n",
    "\n",
    "#imputer = Imputer(\n",
    "#    inputCols=['_c7','_c8'],\n",
    "#    outputCols = [\"{}_imputed\".format(c) for c in ['_c7','_c8'] ]\n",
    "#).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add imputation cols to df\n",
    "#imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Important for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+--------+------------+---------+----------+----+---+---+----+\n",
      "|_c0|        _c1|       _c2|     _c3|         _c4|      _c5|       _c6| _c7|_c8|_c9|_c10|\n",
      "+---+-----------+----------+--------+------------+---------+----------+----+---+---+----+\n",
      "|198|     Donald|  OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK|2600| - |124|  50|\n",
      "|199|    Douglas|     Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK|2600| - |124|  50|\n",
      "|200|   Jennifer|    Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST|4400| - |101|  10|\n",
      "|202|        Pat|       Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP|6000| - |201|  20|\n",
      "|203|      Susan|    Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP|6500| - |101|  40|\n",
      "|104|      Bruce|     Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG|6000| - |103|  60|\n",
      "|105|      David|    Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG|4800| - |103|  60|\n",
      "|106|      Valli| Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG|4800| - |103|  60|\n",
      "|107|      Diana|   Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG|4200| - |103|  60|\n",
      "|111|     Ismael|   Sciarra|ISCIARRA|515.124.4369|30-SEP-05|FI_ACCOUNT|7700| - |108| 100|\n",
      "|112|Jose Manuel|     Urman| JMURMAN|515.124.4469|07-MAR-06|FI_ACCOUNT|7800| - |108| 100|\n",
      "|113|       Luis|      Popp|   LPOPP|515.124.4567|07-DEC-07|FI_ACCOUNT|6900| - |108| 100|\n",
      "|115|  Alexander|      Khoo|   AKHOO|515.127.4562|18-MAY-03|  PU_CLERK|3100| - |114|  30|\n",
      "|116|     Shelli|     Baida|  SBAIDA|515.127.4563|24-DEC-05|  PU_CLERK|2900| - |114|  30|\n",
      "|117|      Sigal|    Tobias| STOBIAS|515.127.4564|24-JUL-05|  PU_CLERK|2800| - |114|  30|\n",
      "|118|        Guy|    Himuro| GHIMURO|515.127.4565|15-NOV-06|  PU_CLERK|2600| - |114|  30|\n",
      "|119|      Karen|Colmenares|KCOLMENA|515.127.4566|10-AUG-07|  PU_CLERK|2500| - |114|  30|\n",
      "|120|    Matthew|     Weiss|  MWEISS|650.123.1234|18-JUL-04|    ST_MAN|8000| - |100|  50|\n",
      "|122|      Payam|  Kaufling|PKAUFLIN|650.123.3234|01-MAY-03|    ST_MAN|7900| - |100|  50|\n",
      "|123|     Shanta|   Vollman|SVOLLMAN|650.123.4234|10-OCT-05|    ST_MAN|6500| - |100|  50|\n",
      "+---+-----------+----------+--------+------------+---------+----------+----+---+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Salary of the people less than or equal to 20000\n",
    "\n",
    "df_pyspark.filter('_c7 <= 8000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        _c1|\n",
      "+-----------+\n",
      "|     Donald|\n",
      "|    Douglas|\n",
      "|   Jennifer|\n",
      "|        Pat|\n",
      "|      Susan|\n",
      "|      Bruce|\n",
      "|      David|\n",
      "|      Valli|\n",
      "|      Diana|\n",
      "|     Ismael|\n",
      "|Jose Manuel|\n",
      "|       Luis|\n",
      "|  Alexander|\n",
      "|     Shelli|\n",
      "|      Sigal|\n",
      "|        Guy|\n",
      "|      Karen|\n",
      "|    Matthew|\n",
      "|      Payam|\n",
      "|     Shanta|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter('_c7 <= 8000').select(['_c1']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------+--------+------------+---------+--------+----+---+---+----+\n",
      "|_c0|      _c1|        _c2|     _c3|         _c4|      _c5|     _c6| _c7|_c8|_c9|_c10|\n",
      "+---+---------+-----------+--------+------------+---------+--------+----+---+---+----+\n",
      "|198|   Donald|   OConnell|DOCONNEL|650.507.9833|21-JUN-07|SH_CLERK|2600| - |124|  50|\n",
      "|199|  Douglas|      Grant|  DGRANT|650.507.9844|13-JAN-08|SH_CLERK|2600| - |124|  50|\n",
      "|200| Jennifer|     Whalen| JWHALEN|515.123.4444|17-SEP-03| AD_ASST|4400| - |101|  10|\n",
      "|105|    David|     Austin| DAUSTIN|590.423.4569|25-JUN-05| IT_PROG|4800| - |103|  60|\n",
      "|106|    Valli|  Pataballa|VPATABAL|590.423.4560|05-FEB-06| IT_PROG|4800| - |103|  60|\n",
      "|107|    Diana|    Lorentz|DLORENTZ|590.423.5567|07-FEB-07| IT_PROG|4200| - |103|  60|\n",
      "|115|Alexander|       Khoo|   AKHOO|515.127.4562|18-MAY-03|PU_CLERK|3100| - |114|  30|\n",
      "|116|   Shelli|      Baida|  SBAIDA|515.127.4563|24-DEC-05|PU_CLERK|2900| - |114|  30|\n",
      "|117|    Sigal|     Tobias| STOBIAS|515.127.4564|24-JUL-05|PU_CLERK|2800| - |114|  30|\n",
      "|118|      Guy|     Himuro| GHIMURO|515.127.4565|15-NOV-06|PU_CLERK|2600| - |114|  30|\n",
      "|119|    Karen| Colmenares|KCOLMENA|515.127.4566|10-AUG-07|PU_CLERK|2500| - |114|  30|\n",
      "|125|    Julia|      Nayer|  JNAYER|650.124.1214|16-JUL-05|ST_CLERK|3200| - |120|  50|\n",
      "|126|    Irene|Mikkilineni|IMIKKILI|650.124.1224|28-SEP-06|ST_CLERK|2700| - |120|  50|\n",
      "|127|    James|     Landry| JLANDRY|650.124.1334|14-JAN-07|ST_CLERK|2400| - |120|  50|\n",
      "|128|   Steven|     Markle| SMARKLE|650.124.1434|08-MAR-08|ST_CLERK|2200| - |120|  50|\n",
      "|129|    Laura|     Bissot| LBISSOT|650.124.5234|20-AUG-05|ST_CLERK|3300| - |121|  50|\n",
      "|130|    Mozhe|   Atkinson|MATKINSO|650.124.6234|30-OCT-05|ST_CLERK|2800| - |121|  50|\n",
      "|131|    James|     Marlow| JAMRLOW|650.124.7234|16-FEB-05|ST_CLERK|2500| - |121|  50|\n",
      "|132|       TJ|      Olson| TJOLSON|650.124.8234|10-APR-07|ST_CLERK|2100| - |121|  50|\n",
      "|133|    Jason|     Mallin| JMALLIN|650.127.1934|14-JUN-04|ST_CLERK|3300| - |122|  50|\n",
      "+---+---------+-----------+--------+------------+---------+--------+----+---+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['_c7'] <= 5000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "|_c0|        _c1|      _c2|     _c3|         _c4|      _c5|       _c6|  _c7|_c8|_c9|_c10|\n",
      "+---+-----------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "|201|    Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN|13000| - |100|  20|\n",
      "|202|        Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP| 6000| - |201|  20|\n",
      "|203|      Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP| 6500| - |101|  40|\n",
      "|204|    Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP|10000| - |101|  70|\n",
      "|205|    Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR|12008| - |101| 110|\n",
      "|206|    William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT| 8300| - |205| 110|\n",
      "|103|  Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG| 9000| - |102|  60|\n",
      "|104|      Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG| 6000| - |103|  60|\n",
      "|108|      Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR|12008| - |101| 100|\n",
      "|109|     Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT| 9000| - |108| 100|\n",
      "|110|       John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT| 8200| - |108| 100|\n",
      "|111|     Ismael|  Sciarra|ISCIARRA|515.124.4369|30-SEP-05|FI_ACCOUNT| 7700| - |108| 100|\n",
      "|112|Jose Manuel|    Urman| JMURMAN|515.124.4469|07-MAR-06|FI_ACCOUNT| 7800| - |108| 100|\n",
      "|113|       Luis|     Popp|   LPOPP|515.124.4567|07-DEC-07|FI_ACCOUNT| 6900| - |108| 100|\n",
      "|114|        Den| Raphaely|DRAPHEAL|515.127.4561|07-DEC-02|    PU_MAN|11000| - |100|  30|\n",
      "|120|    Matthew|    Weiss|  MWEISS|650.123.1234|18-JUL-04|    ST_MAN| 8000| - |100|  50|\n",
      "|121|       Adam|    Fripp|  AFRIPP|650.123.2234|10-APR-05|    ST_MAN| 8200| - |100|  50|\n",
      "|122|      Payam| Kaufling|PKAUFLIN|650.123.3234|01-MAY-03|    ST_MAN| 7900| - |100|  50|\n",
      "|123|     Shanta|  Vollman|SVOLLMAN|650.123.4234|10-OCT-05|    ST_MAN| 6500| - |100|  50|\n",
      "|124|      Kevin|  Mourgos|KMOURGOS|650.123.5234|16-NOV-07|    ST_MAN| 5800| - |100|  50|\n",
      "+---+-----------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['_c7'] <= 15000) & \n",
    "                  (df_pyspark['_c7'] >= 5000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "|_c0|      _c1|      _c2|     _c3|         _c4|      _c5|       _c6|  _c7|_c8|_c9|_c10|\n",
      "+---+---------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "|198|   Donald| OConnell|DOCONNEL|650.507.9833|21-JUN-07|  SH_CLERK| 2600| - |124|  50|\n",
      "|199|  Douglas|    Grant|  DGRANT|650.507.9844|13-JAN-08|  SH_CLERK| 2600| - |124|  50|\n",
      "|200| Jennifer|   Whalen| JWHALEN|515.123.4444|17-SEP-03|   AD_ASST| 4400| - |101|  10|\n",
      "|201|  Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN|13000| - |100|  20|\n",
      "|202|      Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP| 6000| - |201|  20|\n",
      "|203|    Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP| 6500| - |101|  40|\n",
      "|204|  Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP|10000| - |101|  70|\n",
      "|205|  Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR|12008| - |101| 110|\n",
      "|206|  William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT| 8300| - |205| 110|\n",
      "|100|   Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES|24000| - | - |  90|\n",
      "|101|    Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP|17000| - |100|  90|\n",
      "|102|      Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP|17000| - |100|  90|\n",
      "|103|Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG| 9000| - |102|  60|\n",
      "|104|    Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG| 6000| - |103|  60|\n",
      "|105|    David|   Austin| DAUSTIN|590.423.4569|25-JUN-05|   IT_PROG| 4800| - |103|  60|\n",
      "|106|    Valli|Pataballa|VPATABAL|590.423.4560|05-FEB-06|   IT_PROG| 4800| - |103|  60|\n",
      "|107|    Diana|  Lorentz|DLORENTZ|590.423.5567|07-FEB-07|   IT_PROG| 4200| - |103|  60|\n",
      "|108|    Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR|12008| - |101| 100|\n",
      "|109|   Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT| 9000| - |108| 100|\n",
      "|110|     John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT| 8200| - |108| 100|\n",
      "+---+---------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## OR\n",
    "\n",
    "df_pyspark.filter((df_pyspark['_c7'] <= 15000) |\n",
    "                  (df_pyspark['_c7'] >= 5000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "|_c0|        _c1|      _c2|     _c3|         _c4|      _c5|       _c6|  _c7|_c8|_c9|_c10|\n",
      "+---+-----------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "|201|    Michael|Hartstein|MHARTSTE|515.123.5555|17-FEB-04|    MK_MAN|13000| - |100|  20|\n",
      "|202|        Pat|      Fay|    PFAY|603.123.6666|17-AUG-05|    MK_REP| 6000| - |201|  20|\n",
      "|203|      Susan|   Mavris| SMAVRIS|515.123.7777|07-JUN-02|    HR_REP| 6500| - |101|  40|\n",
      "|204|    Hermann|     Baer|   HBAER|515.123.8888|07-JUN-02|    PR_REP|10000| - |101|  70|\n",
      "|205|    Shelley|  Higgins|SHIGGINS|515.123.8080|07-JUN-02|    AC_MGR|12008| - |101| 110|\n",
      "|206|    William|    Gietz|  WGIETZ|515.123.8181|07-JUN-02|AC_ACCOUNT| 8300| - |205| 110|\n",
      "|100|     Steven|     King|   SKING|515.123.4567|17-JUN-03|   AD_PRES|24000| - | - |  90|\n",
      "|101|      Neena|  Kochhar|NKOCHHAR|515.123.4568|21-SEP-05|     AD_VP|17000| - |100|  90|\n",
      "|102|        Lex|  De Haan| LDEHAAN|515.123.4569|13-JAN-01|     AD_VP|17000| - |100|  90|\n",
      "|103|  Alexander|   Hunold| AHUNOLD|590.423.4567|03-JAN-06|   IT_PROG| 9000| - |102|  60|\n",
      "|104|      Bruce|    Ernst|  BERNST|590.423.4568|21-MAY-07|   IT_PROG| 6000| - |103|  60|\n",
      "|108|      Nancy|Greenberg|NGREENBE|515.124.4569|17-AUG-02|    FI_MGR|12008| - |101| 100|\n",
      "|109|     Daniel|   Faviet| DFAVIET|515.124.4169|16-AUG-02|FI_ACCOUNT| 9000| - |108| 100|\n",
      "|110|       John|     Chen|   JCHEN|515.124.4269|28-SEP-05|FI_ACCOUNT| 8200| - |108| 100|\n",
      "|111|     Ismael|  Sciarra|ISCIARRA|515.124.4369|30-SEP-05|FI_ACCOUNT| 7700| - |108| 100|\n",
      "|112|Jose Manuel|    Urman| JMURMAN|515.124.4469|07-MAR-06|FI_ACCOUNT| 7800| - |108| 100|\n",
      "|113|       Luis|     Popp|   LPOPP|515.124.4567|07-DEC-07|FI_ACCOUNT| 6900| - |108| 100|\n",
      "|114|        Den| Raphaely|DRAPHEAL|515.127.4561|07-DEC-02|    PU_MAN|11000| - |100|  30|\n",
      "|120|    Matthew|    Weiss|  MWEISS|650.123.1234|18-JUL-04|    ST_MAN| 8000| - |100|  50|\n",
      "|121|       Adam|    Fripp|  AFRIPP|650.123.2234|10-APR-05|    ST_MAN| 8200| - |100|  50|\n",
      "+---+-----------+---------+--------+------------+---------+----------+-----+---+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Inverse Filter Operation\n",
    "\n",
    "df_pyspark.filter(~(df_pyspark['_c7'] <= 15000) |\n",
    "                  (df_pyspark['_c7'] >= 5000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy And Aggregate Functions\n",
    "\n",
    "(For Data Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GroupBy\n",
    "# Q. What will be the mean avg salary?\n",
    "\n",
    "# df_pyspark.groupby('_c1').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o308.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 32.0 failed 1 times, most recent failure: Lost task 0.0 in stage 32.0 (TID 31) (PREDATOR executor driver): java.nio.file.NoSuchFileException: C:\\Users\\Swapnil\\AppData\\Local\\Temp\\blockmgr-478d9285-e07a-47ba-9e69-399b5fb8c222\\16\r\n\tat sun.nio.fs.WindowsException.translateToIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsFileSystemProvider.createDirectory(Unknown Source)\r\n\tat java.nio.file.Files.createDirectory(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:108)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:126)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.$anonfun$getDataFile$2(IndexShuffleBlockResolver.scala:103)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:103)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:65)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleMapOutputWriter.<init>(LocalDiskShuffleMapOutputWriter.java:78)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleExecutorComponents.createMapOutputWriter(LocalDiskShuffleExecutorComponents.java:71)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:138)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.nio.file.NoSuchFileException: C:\\Users\\Swapnil\\AppData\\Local\\Temp\\blockmgr-478d9285-e07a-47ba-9e69-399b5fb8c222\\16\r\n\tat sun.nio.fs.WindowsException.translateToIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsFileSystemProvider.createDirectory(Unknown Source)\r\n\tat java.nio.file.Files.createDirectory(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:108)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:126)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.$anonfun$getDataFile$2(IndexShuffleBlockResolver.scala:103)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:103)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:65)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleMapOutputWriter.<init>(LocalDiskShuffleMapOutputWriter.java:78)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleExecutorComponents.createMapOutputWriter(LocalDiskShuffleExecutorComponents.java:71)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:138)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32me:\\PySpark\\pyspark.ipynb Cell 50\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PySpark/pyspark.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Groupby department\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/PySpark/pyspark.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Q. Which department gets amx salary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/PySpark/pyspark.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_pyspark\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39m_c6\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32me:\\PySpark\\myenv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:899\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[39mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    894\u001b[0m         error_class\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNOT_BOOL\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    895\u001b[0m         message_parameters\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39marg_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marg_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(vertical)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(truncate, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m truncate:\n\u001b[1;32m--> 899\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mshowString(n, \u001b[39m20\u001b[39;49m, vertical))\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    901\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32me:\\PySpark\\myenv\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32me:\\PySpark\\myenv\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32me:\\PySpark\\myenv\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o308.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 32.0 failed 1 times, most recent failure: Lost task 0.0 in stage 32.0 (TID 31) (PREDATOR executor driver): java.nio.file.NoSuchFileException: C:\\Users\\Swapnil\\AppData\\Local\\Temp\\blockmgr-478d9285-e07a-47ba-9e69-399b5fb8c222\\16\r\n\tat sun.nio.fs.WindowsException.translateToIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsFileSystemProvider.createDirectory(Unknown Source)\r\n\tat java.nio.file.Files.createDirectory(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:108)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:126)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.$anonfun$getDataFile$2(IndexShuffleBlockResolver.scala:103)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:103)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:65)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleMapOutputWriter.<init>(LocalDiskShuffleMapOutputWriter.java:78)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleExecutorComponents.createMapOutputWriter(LocalDiskShuffleExecutorComponents.java:71)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:138)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.nio.file.NoSuchFileException: C:\\Users\\Swapnil\\AppData\\Local\\Temp\\blockmgr-478d9285-e07a-47ba-9e69-399b5fb8c222\\16\r\n\tat sun.nio.fs.WindowsException.translateToIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\r\n\tat sun.nio.fs.WindowsFileSystemProvider.createDirectory(Unknown Source)\r\n\tat java.nio.file.Files.createDirectory(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:108)\r\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:126)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.$anonfun$getDataFile$2(IndexShuffleBlockResolver.scala:103)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:103)\r\n\tat org.apache.spark.shuffle.IndexShuffleBlockResolver.getDataFile(IndexShuffleBlockResolver.scala:65)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleMapOutputWriter.<init>(LocalDiskShuffleMapOutputWriter.java:78)\r\n\tat org.apache.spark.shuffle.sort.io.LocalDiskShuffleExecutorComponents.createMapOutputWriter(LocalDiskShuffleExecutorComponents.java:71)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:138)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "## Groupby department\n",
    "# Q. Which department gets max salary\n",
    "\n",
    "df_pyspark.groupby('_c6').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
